# SPDX-License-Identifier: MIT
# Copyright (c) 2026 MuVeraAI Corporation
"""
trust_convergence â€” Research simulation for Paper 13.

NOTE: This is a SIMULATION package for academic research reproduction.
It does NOT contain the production trust progression algorithm.
All data generated by this package is SYNTHETIC.

Typical usage
-------------
>>> from trust_convergence.scenarios import SCENARIOS
>>> from trust_convergence.model import TrustProgressionModel
>>> from trust_convergence.agents import CompliantAgent
>>> model = TrustProgressionModel(SCENARIOS["baseline"])
>>> result = model.simulate(CompliantAgent(quality=0.8, seed=42))
>>> result.final_level > 0
True
"""
from trust_convergence.agents import (
    AdversarialAgent,
    AgentBehavior,
    CompliantAgent,
    DegradingAgent,
    MixedAgent,
    PeriodicAgent,
)
from trust_convergence.metrics import (
    area_under_trajectory,
    convergence_bound,
    convergence_rate,
    mean_trust_level,
    stability_index,
    time_to_first_peak,
)
from trust_convergence.model import (
    SimulationConfig,
    SimulationResult,
    TrustProgressionModel,
)
from trust_convergence.scenarios import SCENARIOS, get_scenario, list_scenarios

__all__ = [
    # Model
    "SimulationConfig",
    "SimulationResult",
    "TrustProgressionModel",
    # Agents
    "AgentBehavior",
    "CompliantAgent",
    "AdversarialAgent",
    "MixedAgent",
    "DegradingAgent",
    "PeriodicAgent",
    # Metrics
    "convergence_rate",
    "stability_index",
    "convergence_bound",
    "mean_trust_level",
    "area_under_trajectory",
    "time_to_first_peak",
    # Scenarios
    "SCENARIOS",
    "get_scenario",
    "list_scenarios",
]

__version__ = "0.1.0"
__author__ = "MuVeraAI Research"
__license__ = "MIT"
